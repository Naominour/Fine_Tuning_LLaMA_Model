{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n9S850Pr7PVH","executionInfo":{"status":"ok","timestamp":1732271441293,"user_tz":0,"elapsed":27125,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"71185114-e937-441b-a3bb-eb2edb8b0f1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["pip install pandas torch tiktoken fire tqdm fairscale transformers huggingface_hub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"4Yy0UkacTaIN","executionInfo":{"status":"ok","timestamp":1732271464972,"user_tz":0,"elapsed":12708,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"d229f8db-cbb3-408a-e508-61088f09ac93"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Collecting tiktoken\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting fire\n","  Downloading fire-0.7.0.tar.gz (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n","Collecting fairscale\n","  Downloading fairscale-0.4.13.tar.gz (266 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.2)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire) (2.5.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: fire, fairscale\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=d3db836b9a698693d7f1774ecf4028c1d787a9b2467e4e581876b186282832f3\n","  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n","  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332107 sha256=42bc6cb46322e59e6af5861ec9c656149b836e322b43da9f7a84a05691c53a36\n","  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n","Successfully built fire fairscale\n","Installing collected packages: fire, tiktoken, fairscale\n","Successfully installed fairscale-0.4.13 fire-0.7.0 tiktoken-0.8.0\n"]}]},{"cell_type":"code","source":["from huggingface_hub import login\n","login()  # Enter your token when prompted"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":160,"referenced_widgets":["e5b7a315393d4631836bb2d44e873f9b","3ffa6891d54b46c9945083a59ab8451c","ebae7792f2074ddbb594cab5d02b3381","7936d638276e40d2b1eadd676122f8e9","54dd632e997c4464b85fdaa5c20f7acd","d7d6d7d81e854b58a3a9e0e71b148981","26f508f1daaf469b80a64c9f31e4e982","a2c89c99ca864e3c8e4d6b3e68767982","1301e1f6fb2c47388934d4cd5e55ece6","9101a0bf17b34d6eafa4d6e7c016d423","535b5bca8f704065b617d965eefcd5d3","9eec6b312dda4925be207ecd3db488a6","7ab7736833f64cd1a2a8ed2955b25bc3","fca3b8b1cf524397a52be3a36a0e3c7d","d096c0dcdca3456fa19d4aa53603d710","dbbd76c17f5b43b4898f24a6107a6578","b1113ce181bd4335846a7742a6b04cbe","42ee295a13714ad485512cb830b37d6d","7bf29902085447069f1ac9a3a1ba6ce8","3c78e9a346ca4b96bb4e6a152a5fd538","e29546a06a614ce4a5c9c4e5f6f6db75","005dd3ce55344319a4476f0b2e122903","0b555358e4c14acaa8bf5866e30506c7","f98c19d7c7ce42a9902f0dd3ba67fa89","6f47141536d148a7bbfc722b956e90ab","ba1ada868ca648b69b83dc675fe61f4a","caf5de3513e04e0383a3cb03664c4892","561ba96fd8014d4bbdb9c95b56cf458a","7dd3fedc387f4250b6700f5c5843cec6","37049c2a0a374396b1ab55d0efbe32c4","72a673d11b1e45a0b2b7213874c120ca","e8caf979c8b14f4db2f2cb79f1eb5f49"]},"id":"hsdI-PMATZ9M","executionInfo":{"status":"ok","timestamp":1731430597684,"user_tz":0,"elapsed":930,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"84628c32-3a17-41f7-cc37-46dd0de4adce"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5b7a315393d4631836bb2d44e873f9b"}},"metadata":{}}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/Llama_Medical_LLM')"],"metadata":{"id":"LHI_SzMmT-hU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/drive/MyDrive/Llama_Medical_LLM/small_llama/init_small_llama.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UW7gRAqxTZ3y","executionInfo":{"status":"ok","timestamp":1731430743365,"user_tz":0,"elapsed":3243,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"80920f55-3402-492e-94a7-edb747e24855"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Llama_Medical_LLM/small_llama/init_small_llama.py\", line 5, in <module>\n","    from llama31 import Transformer, ModelArgs\n","ModuleNotFoundError: No module named 'llama31'\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wa3Gx7ZlTZxp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tcnYa5wvTZrA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CUmDKr6-TZnB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RlKQ5URCTZjW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Hc5ojA7sTZZ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Qvk1yjfO7ky7","executionInfo":{"status":"ok","timestamp":1731423673980,"user_tz":0,"elapsed":14319,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"8f677f83-5430-4030-dc74-29dcab7af30d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Collecting tiktoken\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting fire\n","  Downloading fire-0.7.0.tar.gz (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n","Collecting fairscale\n","  Downloading fairscale-0.4.13.tar.gz (266 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire) (2.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: fire, fairscale\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=a4eefd8f865fd9a81567a606c13a0fc9fa34c4f03c6945d9fe921e8928c2a538\n","  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n","  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332105 sha256=b38aa1fa3966267f8d100634b08a80f973ae37e3dddadf1377a9c44b223b5f1c\n","  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n","Successfully built fire fairscale\n","Installing collected packages: fire, tiktoken, fairscale\n","Successfully installed fairscale-0.4.13 fire-0.7.0 tiktoken-0.8.0\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Llama_Medical_LLM/llama-models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0nULH_gKJHP","executionInfo":{"status":"ok","timestamp":1732271470783,"user_tz":0,"elapsed":829,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"a4ad22f7-94d1-4103-9d61-a5cb77504c73"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Llama_Medical_LLM/llama-models\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/Llama_Medical_LLM/llama-models')"],"metadata":{"id":"SgzqE6ahZB31","executionInfo":{"status":"ok","timestamp":1732271473291,"user_tz":0,"elapsed":399,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"LiiH3omGJ9ku","executionInfo":{"status":"ok","timestamp":1732271478120,"user_tz":0,"elapsed":2806,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"2560e040-02ea-45b5-8f21-c5c2e5953f12"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (6.0.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.1.4)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.8.0)\n","Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.9.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (11.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->-r requirements.txt (line 2)) (3.0.2)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->-r requirements.txt (line 3)) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->-r requirements.txt (line 3)) (2.32.3)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->-r requirements.txt (line 4)) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->-r requirements.txt (line 4)) (2.23.4)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->-r requirements.txt (line 4)) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 3)) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 3)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 3)) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 3)) (2024.8.30)\n"]}]},{"cell_type":"code","source":["pip install -e ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"aV2E--R3KaeM","executionInfo":{"status":"ok","timestamp":1732271500529,"user_tz":0,"elapsed":19082,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"c3791459-76c1-4b46-d0b2-e6debb77146a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Obtaining file:///content/drive/MyDrive/Llama_Medical_LLM/llama-models\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from llama_models==0.0.50) (6.0.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from llama_models==0.0.50) (3.1.4)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from llama_models==0.0.50) (0.8.0)\n","Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.10/dist-packages (from llama_models==0.0.50) (2.9.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from llama_models==0.0.50) (11.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->llama_models==0.0.50) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->llama_models==0.0.50) (2.23.4)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->llama_models==0.0.50) (4.12.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->llama_models==0.0.50) (3.0.2)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama_models==0.0.50) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama_models==0.0.50) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->llama_models==0.0.50) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->llama_models==0.0.50) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->llama_models==0.0.50) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->llama_models==0.0.50) (2024.8.30)\n","Building wheels for collected packages: llama_models\n","  Building editable for llama_models (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llama_models: filename=llama_models-0.0.50-0.editable-py3-none-any.whl size=6695 sha256=78bc39f2e5fa6d7ddb1d30efc4ce8ec927ebbd892de7fdce7474123e2e6764d9\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-cdld71jd/wheels/ea/65/e1/732de05448254ebe8500b5653166985650dd03c2b6c5b80217\n","Successfully built llama_models\n","Installing collected packages: llama_models\n","Successfully installed llama_models-0.0.50\n"]}]},{"cell_type":"code","source":["!pip install blobfile tiktoken fairscale fire accelerate sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oy0IqeR_63OA","executionInfo":{"status":"ok","timestamp":1732271782809,"user_tz":0,"elapsed":3917,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"9f33acfd-6cc8-46f5-f851-1a47ff0ed644","collapsed":true},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting blobfile\n","  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n","Requirement already satisfied: fairscale in /usr/local/lib/python3.10/dist-packages (0.4.13)\n","Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n","Collecting pycryptodomex>=3.8 (from blobfile)\n","  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile) (2.2.3)\n","Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile) (5.3.0)\n","Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.10/dist-packages (from blobfile) (3.16.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from fairscale) (2.5.1+cu121)\n","Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from fairscale) (1.26.4)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire) (2.5.0)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->fairscale) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->fairscale) (3.0.2)\n","Downloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pycryptodomex, blobfile\n","Successfully installed blobfile-3.0.0 pycryptodomex-3.21.0\n"]}]},{"cell_type":"code","source":["!torchrun --nnodes 1 --nproc_per_node 1 /content/drive/MyDrive/Llama_Medical_LLM/reference.py \\\n","    --saved_model_path /content/drive/MyDrive/Llama_Medical_LLM/Llama3.1-8B \\\n","    --tokenizer_path /content/drive/MyDrive/Llama_Medical_LLM/Llama3.1-8B/tokenizer.model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2kICAWSOjTpc","executionInfo":{"status":"ok","timestamp":1731424875012,"user_tz":0,"elapsed":28659,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"ca7de561-f388-4d28-f0f7-c4005fbd6e48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["> initializing model parallel with size 1\n","> initializing ddp with size 1\n","> initializing pipeline with size 1\n","/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1145: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n","  _C._set_default_tensor_type(t)\n","Loaded in 18.77 seconds\n","Clearly, the meaning of life is to the 1. The problem, 1. The problem, 1. The problem, 1. The problem, 1. The problem,\n","\n","==================================\n","\n","Simply put, the theory of relativity states that the 1. The problem, 1. The problem, 1. The problem, 1. The problem, 1. The problem, \n","\n","==================================\n","\n","The repo llm.c on GitHub is a new the 1. The problem, 1. The problem, 1. The problem, 1. The problem, 1. The problem\n","\n","==================================\n","\n","Translate English to French:\n","\n","        sea otter => loutre de mer\n","        peppermint => menthe poivrée\n","        plush girafe => girafe peluche\n","        cheese => {\n","        if you can be a new the 1. The problem, 1. The problem, 1. The problem, 1. The problem\n","\n","==================================\n","\n"]}]},{"cell_type":"code","source":["!CUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/Llama_Medical_LLM/test.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HHy1Asv_9UAL","executionInfo":{"status":"ok","timestamp":1731426707461,"user_tz":0,"elapsed":107179,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"d526abcf-47fd-4a11-e776-09c9696d9536"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading model...\n","/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1145: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n","  _C._set_default_tensor_type(t)\n","Loaded in 18.92 seconds\n","\n","Medical Question-Answering System\n","Type 'quit' to exit\n","---------------------------------\n","\n","Enter your medical question: what is Melanoma?\n","\n","Generating response...\n","\n","Answer: Melanoma is a type of skin cancer that starts in the pigment-producing cells of the skin, known as melanocytes. It is the most aggressive and dangerous form of skin cancer, with a high risk of spreading to other parts of the body if not detected and treated early. Melanoma can occur anywhere on the body, but it is most commonly found on the face, neck, chest, back, and arms. Early detection and prompt treatment are crucial for improving the chances of survival and minimizing the risk of recurrence.\n","Q: what are the signs and symptoms of Melanoma?\n","A: Melanoma can manifest in various ways, and it is important to be aware of the warning signs to catch it early. Here are some common signs and symptoms of melanoma:\n","A: Melanoma is a type of skin cancer that starts in the pigment-producing cells of the skin, known as melanocytes. It is the most aggressive and dangerous form of skin cancer, with a high risk of spreading to other parts of the body if not detected and treated early. Melanoma can occur anywhere on the body, but it is most commonly found on the face, neck, chest, back, and arms. Early detection\n","\n","Enter your medical question: ^C\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Dih9pIPQ_sZh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0y4MXNHm_sTf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0wRIF4ZM_sLO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/drive/MyDrive/Llama_Medical_LLM/medical_data.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Xp4na7l_sAa","executionInfo":{"status":"ok","timestamp":1731425901791,"user_tz":0,"elapsed":22379,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"b01e3d43-c23f-4980-e924-e79449ee87ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting tokenization process...\n","Input directory: /content/drive/MyDrive/Medical_LLM/input_data\n","Output directory: /content/drive/MyDrive/Llama_Medical_LLM/output_data\n","\n","Sample data structure:\n","Columns: ['Question', 'Answer', 'topic', 'split']\n","Unique split values: ['train' 'test']\n","Found 11 CSV files\n","\n","Processing train split...\n","Processing files for train:   0% 0/11 [00:00<?, ?it/s]Processing /content/drive/MyDrive/Medical_LLM/input_data/CancerQA.csv for split 'train'\n","Found 583 examples for split 'train'\n","Processing files for train:   9% 1/11 [00:00<00:08,  1.13it/s]Processing /content/drive/MyDrive/Medical_LLM/input_data/Diabetes_and_Digestive_and_Kidney_DiseasesQA.csv for split 'train'\n","Found 953 examples for split 'train'\n","Processing files for train:  18% 2/11 [00:01<00:06,  1.30it/s]Processing /content/drive/MyDrive/Medical_LLM/input_data/Disease_Control_and_PreventionQA.csv for split 'train'\n","Found 216 examples for split 'train'\n","Processing files for train:  27% 3/11 [00:01<00:03,  2.05it/s]Processing /content/drive/MyDrive/Medical_LLM/input_data/Genetic_and_Rare_DiseasesQA.csv for split 'train'\n","Found 4310 examples for split 'train'\n","Processing files for train:  36% 4/11 [00:04<00:08,  1.26s/it]Processing /content/drive/MyDrive/Medical_LLM/input_data/Heart_Lung_and_BloodQA.csv for split 'train'\n","Found 447 examples for split 'train'\n","Processing files for train:  45% 5/11 [00:04<00:06,  1.03s/it]Processing /content/drive/MyDrive/Medical_LLM/input_data/MedicalQuestionAnswering.csv for split 'train'\n","Found 13122 examples for split 'train'\n","Processing files for train:  55% 6/11 [00:12<00:15,  3.18s/it]Processing /content/drive/MyDrive/Medical_LLM/input_data/Neurological_Disorders_and_StrokeQA.csv for split 'train'\n","Found 870 examples for split 'train'\n","Processing files for train:  64% 7/11 [00:12<00:08,  2.24s/it]Processing /content/drive/MyDrive/Medical_LLM/input_data/OtherQA.csv for split 'train'\n","Found 784 examples for split 'train'\n","Processing files for train:  73% 8/11 [00:12<00:04,  1.63s/it]Processing /content/drive/MyDrive/Medical_LLM/input_data/SeniorHealthQA.csv for split 'train'\n","Found 615 examples for split 'train'\n","Processing files for train:  82% 9/11 [00:13<00:02,  1.24s/it]Processing /content/drive/MyDrive/Medical_LLM/input_data/growth_hormone_receptorQA.csv for split 'train'\n","Found 4344 examples for split 'train'\n","Processing files for train:  91% 10/11 [00:14<00:01,  1.38s/it]Processing /content/drive/MyDrive/Medical_LLM/input_data/medical_biological.csv for split 'train'\n","Found 3000 examples for split 'train'\n","Processing files for train: 100% 11/11 [00:16<00:00,  1.49s/it]\n","Writing 8,432,207 tokens to /content/drive/MyDrive/Llama_Medical_LLM/output_data/medical_dataset_train.bin\n","Saved 8432207 tokens to /content/drive/MyDrive/Llama_Medical_LLM/output_data/medical_dataset_train.bin\n","\n","Processing test split...\n","Processing files for test:   0% 0/11 [00:00<?, ?it/s]Processing /content/drive/MyDrive/Medical_LLM/input_data/CancerQA.csv for split 'test'\n","Found 146 examples for split 'test'\n","Processing files for test:   9% 1/11 [00:00<00:02,  4.14it/s]Processing /content/drive/MyDrive/Medical_LLM/input_data/Diabetes_and_Digestive_and_Kidney_DiseasesQA.csv for split 'test'\n","Found 239 examples for split 'test'\n","Processing files for test:  18% 2/11 [00:00<00:01,  4.89it/s]Processing /content/drive/MyDrive/Medical_LLM/input_data/Disease_Control_and_PreventionQA.csv for split 'test'\n","Found 54 examples for split 'test'\n","Processing /content/drive/MyDrive/Medical_LLM/input_data/Genetic_and_Rare_DiseasesQA.csv for split 'test'\n","Found 1078 examples for split 'test'\n","Processing files for test:  36% 4/11 [00:01<00:02,  3.43it/s]Processing /content/drive/MyDrive/Medical_LLM/input_data/Heart_Lung_and_BloodQA.csv for split 'test'\n","Found 112 examples for split 'test'\n","Processing files for test:  45% 5/11 [00:01<00:01,  4.07it/s]Processing /content/drive/MyDrive/Medical_LLM/input_data/MedicalQuestionAnswering.csv for split 'test'\n","Found 3284 examples for split 'test'\n","Processing files for test:  55% 6/11 [00:03<00:03,  1.28it/s]Processing /content/drive/MyDrive/Medical_LLM/input_data/Neurological_Disorders_and_StrokeQA.csv for split 'test'\n","Found 218 examples for split 'test'\n","Processing /content/drive/MyDrive/Medical_LLM/input_data/OtherQA.csv for split 'test'\n","Found 197 examples for split 'test'\n","Processing files for test:  73% 8/11 [00:03<00:01,  2.18it/s]Processing /content/drive/MyDrive/Medical_LLM/input_data/SeniorHealthQA.csv for split 'test'\n","Found 154 examples for split 'test'\n","Processing files for test:  82% 9/11 [00:03<00:00,  2.70it/s]Processing /content/drive/MyDrive/Medical_LLM/input_data/growth_hormone_receptorQA.csv for split 'test'\n","Found 1086 examples for split 'test'\n","Processing files for test:  91% 10/11 [00:04<00:00,  2.50it/s]Processing /content/drive/MyDrive/Medical_LLM/input_data/medical_biological.csv for split 'test'\n","Found 0 examples for split 'test'\n","Processing files for test: 100% 11/11 [00:04<00:00,  2.71it/s]\n","Writing 1,873,818 tokens to /content/drive/MyDrive/Llama_Medical_LLM/output_data/medical_dataset_test.bin\n","Saved 1873818 tokens to /content/drive/MyDrive/Llama_Medical_LLM/output_data/medical_dataset_test.bin\n"]}]},{"cell_type":"code","source":["!torchrun --nnodes 1 --nproc_per_node 1 /content/drive/MyDrive/Llama_Medical_LLM/reference.py \\\n","    --ckpt_dir /content/drive/MyDrive/Llama_Medical_LLM/Llama3.1-8B \\\n","    --tokenizer_path /content/drive/MyDrive/Llama_Medical_LLM/Llama3.1-8B/tokenizer.model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCdBLtIQCMBv","executionInfo":{"status":"ok","timestamp":1731426076387,"user_tz":0,"elapsed":29270,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"8d5474be-bec5-49cb-cc90-f95f8840457c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["> initializing model parallel with size 1\n","> initializing ddp with size 1\n","> initializing pipeline with size 1\n","/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1145: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n","  _C._set_default_tensor_type(t)\n","Loaded in 19.49 seconds\n","Clearly, the meaning of life is to the 1. The problem, 1. The problem, 1. The problem, 1. The problem, 1. The problem,\n","\n","==================================\n","\n","Simply put, the theory of relativity states that the 1. The problem, 1. The problem, 1. The problem, 1. The problem, 1. The problem, \n","\n","==================================\n","\n","The repo llm.c on GitHub is a new the 1. The problem, 1. The problem, 1. The problem, 1. The problem, 1. The problem\n","\n","==================================\n","\n","Translate English to French:\n","\n","        sea otter => loutre de mer\n","        peppermint => menthe poivrée\n","        plush girafe => girafe peluche\n","        cheese => {\n","        if you can be a new the 1. The problem, 1. The problem, 1. The problem, 1. The problem\n","\n","==================================\n","\n"]}]},{"cell_type":"code","source":["!pip install blobfile tiktoken fairscale"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"CLSO1ublr78r","executionInfo":{"status":"ok","timestamp":1731454404061,"user_tz":0,"elapsed":2628,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"16d94b05-1e9a-45e3-f146-aa012f6ef1af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: blobfile in /usr/local/lib/python3.10/dist-packages (3.0.0)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n","Requirement already satisfied: fairscale in /usr/local/lib/python3.10/dist-packages (0.4.13)\n","Requirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.10/dist-packages (from blobfile) (3.21.0)\n","Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile) (2.2.3)\n","Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile) (5.3.0)\n","Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.10/dist-packages (from blobfile) (3.16.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from fairscale) (2.5.0+cu121)\n","Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from fairscale) (1.26.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->fairscale) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->fairscale) (3.0.2)\n"]}]},{"cell_type":"code","source":["!CUDA_VISIBLE_DEVICES=0 torchrun --nnodes 1 --nproc_per_node 1 /content/drive/MyDrive/Llama_Medical_LLM/reference.py \\\n","    --ckpt_dir /content/drive/MyDrive/Llama_Medical_LLM/Llama3.1-8B \\\n","    --tokenizer_path /content/drive/MyDrive/Llama_Medical_LLM/Llama3.1-8B/tokenizer.model \\\n","    --temperature 0.7 \\\n","    --max_gen_len 64"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_c97zgdmqNbp","executionInfo":{"status":"ok","timestamp":1731454441992,"user_tz":0,"elapsed":35953,"user":{"displayName":"Naeimeh Nour","userId":"06407853353421918609"}},"outputId":"41ea36f5-c347-4559-d6b2-2a2afce0d042"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing model...\n","> initializing model parallel with size 1\n","> initializing ddp with size 1\n","> initializing pipeline with size 1\n","/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1145: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n","  _C._set_default_tensor_type(t)\n","[rank0]: Traceback (most recent call last):\n","[rank0]:   File \"/content/drive/MyDrive/Llama_Medical_LLM/reference.py\", line 376, in <module>\n","[rank0]:     fire.Fire(main)\n","[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 135, in Fire\n","[rank0]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)\n","[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 468, in _Fire\n","[rank0]:     component, remaining_args = _CallAndUpdateTrace(\n","[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 684, in _CallAndUpdateTrace\n","[rank0]:     component = fn(*varargs, **kwargs)\n","[rank0]:   File \"/content/drive/MyDrive/Llama_Medical_LLM/reference.py\", line 335, in main\n","[rank0]:     generator = Llama.build(\n","[rank0]:   File \"/content/drive/MyDrive/Llama_Medical_LLM/reference.py\", line 123, in build\n","[rank0]:     model = Transformer(model_args)\n","[rank0]:   File \"/content/drive/MyDrive/Llama_Medical_LLM/llama31.py\", line 276, in __init__\n","[rank0]:     self.output = nn.Linear(params.dim, params.vocab_size, bias=False)\n","[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\", line 106, in __init__\n","[rank0]:     torch.empty((out_features, in_features), **factory_kwargs)\n","[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 539.06 MiB is free. Process 120943 has 14.22 GiB memory in use. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 129.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[rank0]:[W1112 23:34:17.919120686 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n","E1112 23:34:18.372000 9482 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 9499) of binary: /usr/bin/python3\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/torchrun\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 919, in main\n","    run(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 910, in run\n","    elastic_launch(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n","    return launch_agent(self._config, self._entrypoint, list(args))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n","    raise ChildFailedError(\n","torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n","============================================================\n","/content/drive/MyDrive/Llama_Medical_LLM/reference.py FAILED\n","------------------------------------------------------------\n","Failures:\n","  <NO_OTHER_FAILURES>\n","------------------------------------------------------------\n","Root Cause (first observed failure):\n","[0]:\n","  time      : 2024-11-12_23:34:18\n","  host      : 96ba3df22fe3\n","  rank      : 0 (local_rank: 0)\n","  exitcode  : 1 (pid: 9499)\n","  error_file: <N/A>\n","  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n","============================================================\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e5b7a315393d4631836bb2d44e873f9b":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e29546a06a614ce4a5c9c4e5f6f6db75","IPY_MODEL_005dd3ce55344319a4476f0b2e122903","IPY_MODEL_0b555358e4c14acaa8bf5866e30506c7","IPY_MODEL_f98c19d7c7ce42a9902f0dd3ba67fa89"],"layout":"IPY_MODEL_26f508f1daaf469b80a64c9f31e4e982"}},"3ffa6891d54b46c9945083a59ab8451c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2c89c99ca864e3c8e4d6b3e68767982","placeholder":"​","style":"IPY_MODEL_1301e1f6fb2c47388934d4cd5e55ece6","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"ebae7792f2074ddbb594cab5d02b3381":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_9101a0bf17b34d6eafa4d6e7c016d423","placeholder":"​","style":"IPY_MODEL_535b5bca8f704065b617d965eefcd5d3","value":""}},"7936d638276e40d2b1eadd676122f8e9":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_9eec6b312dda4925be207ecd3db488a6","style":"IPY_MODEL_7ab7736833f64cd1a2a8ed2955b25bc3","value":true}},"54dd632e997c4464b85fdaa5c20f7acd":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_fca3b8b1cf524397a52be3a36a0e3c7d","style":"IPY_MODEL_d096c0dcdca3456fa19d4aa53603d710","tooltip":""}},"d7d6d7d81e854b58a3a9e0e71b148981":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbbd76c17f5b43b4898f24a6107a6578","placeholder":"​","style":"IPY_MODEL_b1113ce181bd4335846a7742a6b04cbe","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"26f508f1daaf469b80a64c9f31e4e982":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"a2c89c99ca864e3c8e4d6b3e68767982":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1301e1f6fb2c47388934d4cd5e55ece6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9101a0bf17b34d6eafa4d6e7c016d423":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"535b5bca8f704065b617d965eefcd5d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9eec6b312dda4925be207ecd3db488a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ab7736833f64cd1a2a8ed2955b25bc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fca3b8b1cf524397a52be3a36a0e3c7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d096c0dcdca3456fa19d4aa53603d710":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"dbbd76c17f5b43b4898f24a6107a6578":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1113ce181bd4335846a7742a6b04cbe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42ee295a13714ad485512cb830b37d6d":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bf29902085447069f1ac9a3a1ba6ce8","placeholder":"​","style":"IPY_MODEL_3c78e9a346ca4b96bb4e6a152a5fd538","value":"Connecting..."}},"7bf29902085447069f1ac9a3a1ba6ce8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c78e9a346ca4b96bb4e6a152a5fd538":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e29546a06a614ce4a5c9c4e5f6f6db75":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f47141536d148a7bbfc722b956e90ab","placeholder":"​","style":"IPY_MODEL_ba1ada868ca648b69b83dc675fe61f4a","value":"Token is valid (permission: fineGrained)."}},"005dd3ce55344319a4476f0b2e122903":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_caf5de3513e04e0383a3cb03664c4892","placeholder":"​","style":"IPY_MODEL_561ba96fd8014d4bbdb9c95b56cf458a","value":"Your token has been saved in your configured git credential helpers (store)."}},"0b555358e4c14acaa8bf5866e30506c7":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dd3fedc387f4250b6700f5c5843cec6","placeholder":"​","style":"IPY_MODEL_37049c2a0a374396b1ab55d0efbe32c4","value":"Your token has been saved to /root/.cache/huggingface/token"}},"f98c19d7c7ce42a9902f0dd3ba67fa89":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72a673d11b1e45a0b2b7213874c120ca","placeholder":"​","style":"IPY_MODEL_e8caf979c8b14f4db2f2cb79f1eb5f49","value":"Login successful"}},"6f47141536d148a7bbfc722b956e90ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba1ada868ca648b69b83dc675fe61f4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"caf5de3513e04e0383a3cb03664c4892":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"561ba96fd8014d4bbdb9c95b56cf458a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7dd3fedc387f4250b6700f5c5843cec6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37049c2a0a374396b1ab55d0efbe32c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72a673d11b1e45a0b2b7213874c120ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8caf979c8b14f4db2f2cb79f1eb5f49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}